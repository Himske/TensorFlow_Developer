{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data (takes about 5-6 minutes in Google Colab)\n",
    "(train_data, test_data), ds_info = tfds.load(name=\"food101\", # target dataset to get from TFDS\n",
    "                                             split=[\"train\", \"validation\"], # what splits of data should we get? note: not all datasets have train, valid, test\n",
    "                                             shuffle_files=False, # shuffle files on download?\n",
    "                                             as_supervised=True, # download data in tuple format (sample, label), e.g. (image, label)\n",
    "                                             with_info=True) # include dataset metadata? if so, tfds.load() returns tuple (data, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie',\n",
       " 'baby_back_ribs',\n",
       " 'baklava',\n",
       " 'beef_carpaccio',\n",
       " 'beef_tartare',\n",
       " 'beet_salad',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'bread_pudding',\n",
       " 'breakfast_burrito']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class names\n",
    "class_names = ds_info.features[\"label\"].names\n",
    "class_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function for preprocessing images\n",
    "def preprocess_img(image, label, img_shape=224):\n",
    "  \"\"\"\n",
    "  Converts image datatype from 'uint8' -> 'float32' and reshapes image to\n",
    "  [img_shape, img_shape, color_channels]\n",
    "  \"\"\"\n",
    "  image = tf.image.resize(image, [img_shape, img_shape]) # reshape to img_shape\n",
    "  return tf.cast(image, tf.float32), label # return (float32_image, label) tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map preprocessing function to training data (and paralellize)\n",
    "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Shuffle train_data and turn it into batches and prefetch it (load it faster)\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Map prepreprocessing function to test data\n",
    "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Turn test data into batches (don't need to shuffle)\n",
    "test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorBoard callback (already have \"create_tensorboard_callback()\" from a previous notebook)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create ModelCheckpoint callback to save model's progress\n",
    "checkpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                      monitor=\"val_accuracy\", # save the model weights with best validation accuracy\n",
    "                                                      save_best_only=True, # only save the best weights\n",
    "                                                      save_weights_only=True, # only save model weights (not whole model)\n",
    "                                                      verbose=0) # don't print out whether or not model is being saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, mixed_precision\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Create base model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB4(include_top=False)\n",
    "base_model.trainable = False # freeze base model layers\n",
    "\n",
    "# Create Functional model \n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "# Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n",
    "# x = preprocessing.Rescaling(1./255)(x)\n",
    "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
    "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
    "x = layers.Dense(len(class_names))(x) # want one output neuron per class \n",
    "# Separate activation of output layer so we can output float32 activations\n",
    "outputs = layers.Activation(tf.keras.activations.softmax, dtype=tf.float32, name=\"softmax_float32\")(x) \n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False float32 <Policy \"float32\">\n",
      "rescaling False float32 <Policy \"float32\">\n",
      "normalization False float32 <Policy \"float32\">\n",
      "tf.math.truediv False float32 <Policy \"float32\">\n",
      "stem_conv_pad False float32 <Policy \"float32\">\n",
      "stem_conv False float32 <Policy \"float32\">\n",
      "stem_bn False float32 <Policy \"float32\">\n",
      "stem_activation False float32 <Policy \"float32\">\n",
      "block1a_dwconv False float32 <Policy \"float32\">\n",
      "block1a_bn False float32 <Policy \"float32\">\n",
      "block1a_activation False float32 <Policy \"float32\">\n",
      "block1a_se_squeeze False float32 <Policy \"float32\">\n",
      "block1a_se_reshape False float32 <Policy \"float32\">\n",
      "block1a_se_reduce False float32 <Policy \"float32\">\n",
      "block1a_se_expand False float32 <Policy \"float32\">\n",
      "block1a_se_excite False float32 <Policy \"float32\">\n",
      "block1a_project_conv False float32 <Policy \"float32\">\n",
      "block1a_project_bn False float32 <Policy \"float32\">\n",
      "block1b_dwconv False float32 <Policy \"float32\">\n",
      "block1b_bn False float32 <Policy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "# Check the layers in the base model and see what dtype policy they're using\n",
    "for layer in model.layers[1].layers[:20]: # only check the first 20 layers to save output space\n",
    "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: training_logs/efficientnetb4_101_classes_all_data_feature_extract/20221024-121201\n",
      "Epoch 1/3\n",
      "2368/2368 [==============================] - 347s 142ms/step - loss: 1.7894 - accuracy: 0.5568 - val_loss: 1.2676 - val_accuracy: 0.6621\n",
      "Epoch 2/3\n",
      "2368/2368 [==============================] - 324s 137ms/step - loss: 1.3113 - accuracy: 0.6568 - val_loss: 1.1712 - val_accuracy: 0.6896\n",
      "Epoch 3/3\n",
      "2368/2368 [==============================] - 324s 137ms/step - loss: 1.1640 - accuracy: 0.6928 - val_loss: 1.1277 - val_accuracy: 0.6976\n"
     ]
    }
   ],
   "source": [
    "# Fit the feature extraction model for 5 epochs with tensorboard and model checkpoint callbacks\n",
    "INITIAL_EPOCHS = 3\n",
    "\n",
    "history_101_food_classes_feature_extract  = model.fit(train_data,\n",
    "                                                      epochs=INITIAL_EPOCHS,\n",
    "                                                      steps_per_epoch=len(train_data),\n",
    "                                                      validation_data=test_data,\n",
    "                                                      validation_steps=int(0.15 * len(test_data)),\n",
    "                                                      callbacks=[model_checkpoint,\n",
    "                                                                 create_tensorboard_callback(dir_name=\"training_logs\",\n",
    "                                                                                             experiment_name=\"efficientnetb4_101_classes_all_data_feature_extract\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 66s 83ms/step - loss: 1.1272 - accuracy: 0.6950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1271567344665527, 0.695049524307251]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model (unsaved version) on whole test dataset\n",
    "results_feature_extract_model = model.evaluate(test_data)\n",
    "results_feature_extract_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: food_vision_big_b4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: food_vision_big_b4\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model locally (if you're using Google Colab, your saved model will Colab instance terminates)\n",
    "model.save(\"food_vision_big_b4\")  # SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model previously saved above\n",
    "loaded_model = tf.keras.models.load_model(\"food_vision_big_b4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 84s 104ms/step - loss: 1.1272 - accuracy: 0.6951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.1271567344665527, 0.695049524307251],\n",
       " [1.127156376838684, 0.6950891017913818])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check loaded model performance (this should be the same as results_feature_extract_model)\n",
    "results_loaded_model = loaded_model.evaluate(test_data)\n",
    "results_feature_extract_model, results_loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all of the layers .trainable variable in the loaded model to True (so they're unfrozen)\n",
    "for layer in loaded_model.layers:\n",
    "    layer.trainable = True # set all layers to trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "# Monitor the val_loss and stop training if it doesn't improve for 3 epochs\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping for more\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "\n",
    "\n",
    "# Create ModelCheckpoint callback to save best model during fine-tuning\n",
    "# Save the best model only\n",
    "# Monitor val_loss while training and save the best model (lowest val_loss)\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint for more\n",
    "checkpoint_path = \"fine_tune_checkpoints/cp.ckpt\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                      save_best_only=True,\n",
    "                                                      monitor=\"val_loss\")\n",
    "\n",
    "# Create ReduceLROnPlateau callback to reduce learning rate when a metric has stopped improving\n",
    "# Once the validation loss stops improving for two or more epochs,\n",
    "# we'll reduce the learning rate by a factor of 5 (e.g. 0.001 to 0.0002).\n",
    "# And to make sure the learning rate doesn't get too low (and potentially result in our model learning nothing),\n",
    "# we'll set the minimum learning rate to 1e-7.\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                 patience=2,\n",
    "                                                 factor=0.2,  # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 verbose=1, # print out when learning rate goes down\n",
    "                                                 min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model ready for fine-tuning\n",
    "# Use the Adam optimizer with a 10x lower than default learning rate\n",
    "loaded_model.compile(loss=\"sparse_categorical_crossentropy\", # sparse_categorical_crossentropy for labels that are *not* one-hot\n",
    "                     optimizer=tf.keras.optimizers.Adam(0.0001), # 10x lower learning rate than the default\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: training_logs/efficientb4_101_classes_all_data_fine_tuning/20221024-125623\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/efficientnetb4/block5b_expand_conv/Conv2D' defined at (most recent call last):\n    File \"C:\\Tools\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Tools\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Tools\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Tools\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Tools\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\cfmni\\AppData\\Local\\Temp\\ipykernel_2344\\2426131565.py\", line 6, in <module>\n      history_101_food_classes_b4_fine_tune = loaded_model.fit(train_data,\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/efficientnetb4/block5b_expand_conv/Conv2D'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 150994944 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17396992 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20791296 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20791296 bytes.\n  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 383082496 bytes.\n  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 383082496 bytes.\n  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 105906176 bytes.\n  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 105906176 bytes.\n\t [[{{node model/efficientnetb4/block5b_expand_conv/Conv2D}}]] [Op:__inference_train_function_113692]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Start to fine-tune (all layers)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Use 100 epochs as the default\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Validate on 15% of the test_data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Use the create_tensorboard_callback, ModelCheckpoint and EarlyStopping callbacks you created eaelier\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Start to fine-tune (all layers)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m history_101_food_classes_b4_fine_tune \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mfit(train_data,\n\u001b[0;32m      7\u001b[0m                                                          epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \u001b[39m# fine-tune for a maximum of 100 epochs\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m                                                          steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_data),\n\u001b[0;32m      9\u001b[0m                                                          validation_data\u001b[39m=\u001b[39;49mtest_data,\n\u001b[0;32m     10\u001b[0m                                                          validation_steps\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39m0.15\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mlen\u001b[39;49m(test_data)), \u001b[39m# validation during training on 15% of test data\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m                                                          callbacks\u001b[39m=\u001b[39;49m[create_tensorboard_callback(\u001b[39m\"\u001b[39;49m\u001b[39mtraining_logs\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mefficientb4_101_classes_all_data_fine_tuning\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m# track the model training logs\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m                                                                     model_checkpoint, \u001b[39m# save only the best model during training\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m                                                                     early_stopping, \u001b[39m# stop model after X epochs of no improvements\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m                                                                     reduce_lr])\n",
      "File \u001b[1;32mc:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'model/efficientnetb4/block5b_expand_conv/Conv2D' defined at (most recent call last):\n    File \"C:\\Tools\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Tools\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Tools\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Tools\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Tools\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\cfmni\\AppData\\Local\\Temp\\ipykernel_2344\\2426131565.py\", line 6, in <module>\n      history_101_food_classes_b4_fine_tune = loaded_model.fit(train_data,\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Gitrepo\\TensorFlow_Developer\\venv\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/efficientnetb4/block5b_expand_conv/Conv2D'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 150994944 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17396992 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20791296 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20791296 bytes.\n  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 383082496 bytes.\n  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 383082496 bytes.\n  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 105906176 bytes.\n  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 105906176 bytes.\n\t [[{{node model/efficientnetb4/block5b_expand_conv/Conv2D}}]] [Op:__inference_train_function_113692]"
     ]
    }
   ],
   "source": [
    "# Start to fine-tune (all layers)\n",
    "# Use 100 epochs as the default\n",
    "# Validate on 15% of the test_data\n",
    "# Use the create_tensorboard_callback, ModelCheckpoint and EarlyStopping callbacks you created eaelier\n",
    "# Start to fine-tune (all layers)\n",
    "history_101_food_classes_b4_fine_tune = loaded_model.fit(train_data,\n",
    "                                                         epochs=100, # fine-tune for a maximum of 100 epochs\n",
    "                                                         steps_per_epoch=len(train_data),\n",
    "                                                         validation_data=test_data,\n",
    "                                                         validation_steps=int(0.15 * len(test_data)), # validation during training on 15% of test data\n",
    "                                                         callbacks=[create_tensorboard_callback(\"training_logs\", \"efficientb4_101_classes_all_data_fine_tuning\"), # track the model training logs\n",
    "                                                                    model_checkpoint, # save only the best model during training\n",
    "                                                                    early_stopping, # stop model after X epochs of no improvements\n",
    "                                                                    reduce_lr]) # reduce the learning rate after X epochs of no improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1526e559032d282e659a510b6528b6ebd532e0fbbc7d83ce4d8b802cef89b3d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
